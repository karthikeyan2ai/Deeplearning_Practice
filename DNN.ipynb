{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN WITH 3 HIDDEN LAYER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 training samples\n",
      "10000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 15\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x, y), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x = x.reshape(60000, 784)\n",
    "x_train = x[0:50000]\n",
    "x_val = x[50000::]\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print(x_val.shape[0], 'validation samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y = keras.utils.to_categorical(y, num_classes)\n",
    "y_train = y[0:50000]\n",
    "y_val=y[50000::]\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN function with SGD optimizer (Momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " def DNN(batchsize,lr):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    sgd = K.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batchsize,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_val, y_val))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('test loss:', score[0])\n",
    "    print('test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 2.1925 - acc: 0.2935 - val_loss: 7.3456 - val_acc: 0.4875\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.9497 - acc: 0.6089 - val_loss: 4.3343 - val_acc: 0.7005\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 1.6358 - acc: 0.7172 - val_loss: 3.3854 - val_acc: 0.7709\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 1.2956 - acc: 0.7734 - val_loss: 2.8279 - val_acc: 0.81415s \n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 1.0185 - acc: 0.8055 - val_loss: 2.4559 - val_acc: 0.8391\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.8302 - acc: 0.8266 - val_loss: 2.2646 - val_acc: 0.8537\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.7070 - acc: 0.8400 - val_loss: 2.1200 - val_acc: 0.8643\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.6239 - acc: 0.8514 - val_loss: 1.9675 - val_acc: 0.8739\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.5648 - acc: 0.8616 - val_loss: 1.8338 - val_acc: 0.8819\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.5209 - acc: 0.8685 - val_loss: 1.7664 - val_acc: 0.8870\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.4872 - acc: 0.8745 - val_loss: 1.6754 - val_acc: 0.8931\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 12s 240us/step - loss: 0.4604 - acc: 0.8798 - val_loss: 1.6508 - val_acc: 0.8951\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.4385 - acc: 0.8838 - val_loss: 1.6101 - val_acc: 0.8966\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.4202 - acc: 0.8877 - val_loss: 1.5459 - val_acc: 0.9017\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.4049 - acc: 0.8910 - val_loss: 1.4967 - val_acc: 0.9048\n",
      "test loss: 0.3733648595571518\n",
      "test accuracy: 0.9016\n"
     ]
    }
   ],
   "source": [
    "DNN(batchsize=1024,lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Batch size to 128 Batch size =128 and learning rate =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.3503 - acc: 0.7081 - val_loss: 2.0391 - val_acc: 0.8687\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.4722 - acc: 0.8771 - val_loss: 1.5103 - val_acc: 0.9038\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 0.3588 - acc: 0.9007 - val_loss: 1.4806 - val_acc: 0.9055\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 0.3137 - acc: 0.9116 - val_loss: 1.2739 - val_acc: 0.9191\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 0.2846 - acc: 0.9189 - val_loss: 1.1224 - val_acc: 0.9293\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 0.2630 - acc: 0.9247 - val_loss: 1.0819 - val_acc: 0.9317\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.2448 - acc: 0.9308 - val_loss: 1.0488 - val_acc: 0.9336\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 0.2294 - acc: 0.9342 - val_loss: 1.0167 - val_acc: 0.9363\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.2159 - acc: 0.9382 - val_loss: 0.9450 - val_acc: 0.9405\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 0.2040 - acc: 0.9423 - val_loss: 0.9107 - val_acc: 0.9423\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 0.1935 - acc: 0.9447 - val_loss: 0.8549 - val_acc: 0.9460\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.1832 - acc: 0.9473 - val_loss: 0.8106 - val_acc: 0.9487\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.1744 - acc: 0.9499 - val_loss: 0.7475 - val_acc: 0.9529\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 0.1663 - acc: 0.9528 - val_loss: 0.7047 - val_acc: 0.9557\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 18s 367us/step - loss: 0.1588 - acc: 0.9546 - val_loss: 0.6992 - val_acc: 0.9558\n",
      "test loss: 0.15726898441538215\n",
      "test accuracy: 0.9521\n"
     ]
    }
   ],
   "source": [
    "DNN(batchsize=128,lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By reducing the batchsize from 1024 to 128 Accuracy has increased from 90 to 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Batch size further to 32 to investigate performance; Batch size =32 and learning rate =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 39s 784us/step - loss: 0.6393 - acc: 0.8342 - val_loss: 1.3859 - val_acc: 0.9119- ETA: 0s - loss: 0.\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.2689 - acc: 0.9232 - val_loss: 1.2027 - val_acc: 0.9239\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 38s 754us/step - loss: 0.2095 - acc: 0.9394 - val_loss: 0.8535 - val_acc: 0.9460\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 43s 859us/step - loss: 0.1718 - acc: 0.9500 - val_loss: 0.6585 - val_acc: 0.9586\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 42s 837us/step - loss: 0.1450 - acc: 0.9574 - val_loss: 0.5913 - val_acc: 0.9629\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 38s 769us/step - loss: 0.1246 - acc: 0.9633 - val_loss: 0.6039 - val_acc: 0.9619\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 38s 755us/step - loss: 0.1089 - acc: 0.9681 - val_loss: 0.5039 - val_acc: 0.9681\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 40s 806us/step - loss: 0.0958 - acc: 0.9725 - val_loss: 0.4674 - val_acc: 0.9705\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 0.0850 - acc: 0.9753 - val_loss: 0.5171 - val_acc: 0.9673- ETA: 0s - loss: 0.0848 - acc: \n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 43s 866us/step - loss: 0.0758 - acc: 0.9775 - val_loss: 0.4651 - val_acc: 0.9710\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 40s 808us/step - loss: 0.0679 - acc: 0.9804 - val_loss: 0.4150 - val_acc: 0.9738\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 46s 915us/step - loss: 0.0613 - acc: 0.9823 - val_loss: 0.4001 - val_acc: 0.9745\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 41s 815us/step - loss: 0.0550 - acc: 0.9847 - val_loss: 0.4092 - val_acc: 0.9740\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 42s 843us/step - loss: 0.0496 - acc: 0.9858 - val_loss: 0.4278 - val_acc: 0.9732-\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 38s 756us/step - loss: 0.0445 - acc: 0.9879 - val_loss: 0.3957 - val_acc: 0.9751\n",
      "test loss: 0.07710769472182728\n",
      "test accuracy: 0.9759\n"
     ]
    }
   ],
   "source": [
    "DNN(batchsize=32,lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By reducing Batch size from 128 to 32 the accuracy has further increased to 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchsize=1 and Learning rate =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 658s 13ms/step - loss: 0.2312 - acc: 0.9271 - val_loss: 0.5314 - val_acc: 0.9665\n",
      "test loss: 0.11279717418067157\n",
      "test accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "DNN(batchsize=1,lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By reducing Batch size from 32 to 1 .The Compute time is too high and for single iteration training accuracy achieved is 92\n",
    "\n",
    "#### As the compute time is too high we will fix our Batch size to 32 and vary the learning rate and check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Learning rate by half to lr=0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 39s 790us/step - loss: 0.6366 - acc: 0.8362 - val_loss: 1.3397 - val_acc: 0.9153\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 37s 745us/step - loss: 0.2668 - acc: 0.9231 - val_loss: 0.9507 - val_acc: 0.9398\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 38s 765us/step - loss: 0.2101 - acc: 0.9391 - val_loss: 0.9046 - val_acc: 0.9424\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 33s 662us/step - loss: 0.1731 - acc: 0.9495 - val_loss: 0.6888 - val_acc: 0.9565\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 42s 841us/step - loss: 0.1460 - acc: 0.9578 - val_loss: 0.5578 - val_acc: 0.9646\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 45s 892us/step - loss: 0.1259 - acc: 0.9634 - val_loss: 0.5107 - val_acc: 0.9677\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 0.1091 - acc: 0.9678 - val_loss: 0.5432 - val_acc: 0.9653\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 38s 752us/step - loss: 0.0961 - acc: 0.9722 - val_loss: 0.4803 - val_acc: 0.9700\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.0854 - acc: 0.9755 - val_loss: 0.4474 - val_acc: 0.9718\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 31s 629us/step - loss: 0.0765 - acc: 0.9777 - val_loss: 0.4743 - val_acc: 0.9703\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 43s 861us/step - loss: 0.0681 - acc: 0.9805 - val_loss: 0.4359 - val_acc: 0.9727\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.0609 - acc: 0.9829 - val_loss: 0.4327 - val_acc: 0.9723\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0548 - acc: 0.9842 - val_loss: 0.3925 - val_acc: 0.9755\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 33s 665us/step - loss: 0.0493 - acc: 0.9867 - val_loss: 0.4109 - val_acc: 0.9743\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 37s 749us/step - loss: 0.0444 - acc: 0.9884 - val_loss: 0.4034 - val_acc: 0.9746\n",
      "test loss: 0.07967538918443025\n",
      "test accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "DNN(batchsize=32,lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Learning rate =0.01 and Batch Size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_89 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 42s 835us/step - loss: 0.6273 - acc: 0.8405 - val_loss: 1.2553 - val_acc: 0.9205\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 42s 847us/step - loss: 0.2699 - acc: 0.9221 - val_loss: 0.9740 - val_acc: 0.9386\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 43s 851us/step - loss: 0.2134 - acc: 0.9381 - val_loss: 0.8009 - val_acc: 0.9490\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 38s 767us/step - loss: 0.1764 - acc: 0.9487 - val_loss: 0.6494 - val_acc: 0.9588\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 0.1497 - acc: 0.9564 - val_loss: 0.5556 - val_acc: 0.9648\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 44s 887us/step - loss: 0.1288 - acc: 0.9632 - val_loss: 0.5221 - val_acc: 0.9671\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 41s 815us/step - loss: 0.1124 - acc: 0.9676 - val_loss: 0.5171 - val_acc: 0.9674\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.0996 - acc: 0.9713 - val_loss: 0.4912 - val_acc: 0.9692ss:\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 43s 857us/step - loss: 0.0877 - acc: 0.9748 - val_loss: 0.5506 - val_acc: 0.9651\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 38s 768us/step - loss: 0.0787 - acc: 0.9781 - val_loss: 0.4338 - val_acc: 0.9728\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 41s 827us/step - loss: 0.0703 - acc: 0.9803 - val_loss: 0.4056 - val_acc: 0.9743\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.0629 - acc: 0.9821 - val_loss: 0.4463 - val_acc: 0.9721\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 43s 863us/step - loss: 0.0564 - acc: 0.9845 - val_loss: 0.3956 - val_acc: 0.9752\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 41s 812us/step - loss: 0.0507 - acc: 0.9860 - val_loss: 0.3855 - val_acc: 0.9756\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.0453 - acc: 0.9882 - val_loss: 0.3841 - val_acc: 0.9758\n",
      "test loss: 0.07659204743197187\n",
      "test accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "DNN(batchsize=32,lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate =0.001 and Batch Size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 36s 725us/step - loss: 0.6282 - acc: 0.8417 - val_loss: 1.2849 - val_acc: 0.9190\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 38s 758us/step - loss: 0.2653 - acc: 0.9232 - val_loss: 0.9291 - val_acc: 0.9416\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 0.2072 - acc: 0.9401 - val_loss: 0.7985 - val_acc: 0.9496\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.1704 - acc: 0.9497 - val_loss: 0.7005 - val_acc: 0.9556A: 1s - loss: 0.1 - ETA: 0s - loss: 0.1705 - acc: 0.9\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 40s 808us/step - loss: 0.1447 - acc: 0.9581 - val_loss: 0.5858 - val_acc: 0.9632\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 40s 797us/step - loss: 0.1246 - acc: 0.9637 - val_loss: 0.5693 - val_acc: 0.9642\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 38s 765us/step - loss: 0.1095 - acc: 0.9677 - val_loss: 0.5180 - val_acc: 0.9672\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 38s 759us/step - loss: 0.0958 - acc: 0.9729 - val_loss: 0.4974 - val_acc: 0.9687\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 40s 802us/step - loss: 0.0847 - acc: 0.9760 - val_loss: 0.5469 - val_acc: 0.9656\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 38s 759us/step - loss: 0.0759 - acc: 0.9784 - val_loss: 0.4554 - val_acc: 0.9711\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.0671 - acc: 0.9812 - val_loss: 0.4406 - val_acc: 0.9725\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.0606 - acc: 0.9829 - val_loss: 0.4330 - val_acc: 0.9727\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 38s 761us/step - loss: 0.0543 - acc: 0.9847 - val_loss: 0.4668 - val_acc: 0.9707\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 41s 816us/step - loss: 0.0487 - acc: 0.9870 - val_loss: 0.4164 - val_acc: 0.9738\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 37s 745us/step - loss: 0.0438 - acc: 0.9887 - val_loss: 0.4417 - val_acc: 0.9722\n",
      "test loss: 0.0820373574842699\n",
      "test accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "DNN(batchsize=32,lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  By reducing learning rate to 0.05, 0.01 and 0.01 accuracy is almost similar 97% and the update is comparitively slower\n",
    "###  For the Given DNN architecture appropriate hyperparameter choice would be\n",
    "### Batchsize of 32 and learning rate = 0.1 can give us fast convergence as well as accuracy of 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
