{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "txcKZJosrTNj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#                                                                                CNN"
      ]
    },
    {
      "metadata": {
        "id": "gLNUPw8VR6Pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "95ca74b1-7492-43d2-dd21-016ee6bd7869"
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import keras\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 15\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x, y), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x = x.reshape(x.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x = x.reshape(x.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x = x.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x[0:50000]\n",
        "x_val = x[50000::]\n",
        "\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x.shape)\n",
        "print(x_train.shape, 'train samples')\n",
        "print(x_val.shape, 'validation samples')\n",
        "print(x_test.shape, 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y = keras.utils.to_categorical(y, num_classes)\n",
        "y_train = y[0:50000]\n",
        "y_val=y[50000::]\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1)\n",
            "(50000, 28, 28, 1) train samples\n",
            "(10000, 28, 28, 1) validation samples\n",
            "(10000, 28, 28, 1) test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AGYAhuDqr_vc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN with 1 Hidden layer 128 kernels (with size 3x3 and maxpooling of 2x2 followed by a feed forward layer with 512 units"
      ]
    },
    {
      "metadata": {
        "id": "iY80wl-yaw5a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def CNN_1hidden(batchsize,lr):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    sgd = optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=False)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batchsize,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_lYHKTGFa7Nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "cd5bfa6a-c769-45e6-d69d-e9e76826be40"
      },
      "cell_type": "code",
      "source": [
        "CNN_1hidden(1024,0.1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 21632)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               2769024   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,771,594\n",
            "Trainable params: 2,771,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 10s 194us/step - loss: 2.2055 - acc: 0.4854 - val_loss: 3.8412 - val_acc: 0.7013\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 4s 82us/step - loss: 1.8504 - acc: 0.7026 - val_loss: 3.3605 - val_acc: 0.7720\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 4s 83us/step - loss: 1.2626 - acc: 0.7781 - val_loss: 2.5992 - val_acc: 0.8311\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 4s 82us/step - loss: 0.8233 - acc: 0.8281 - val_loss: 2.1014 - val_acc: 0.8647\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 4s 82us/step - loss: 0.6210 - acc: 0.8557 - val_loss: 1.8941 - val_acc: 0.8795\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 4s 82us/step - loss: 0.5225 - acc: 0.8696 - val_loss: 1.7799 - val_acc: 0.8854\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 4s 81us/step - loss: 0.4665 - acc: 0.8792 - val_loss: 1.6794 - val_acc: 0.8932\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 4s 81us/step - loss: 0.4306 - acc: 0.8849 - val_loss: 1.5848 - val_acc: 0.8992\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 4s 81us/step - loss: 0.4052 - acc: 0.8898 - val_loss: 1.5428 - val_acc: 0.9019\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 4s 81us/step - loss: 0.3866 - acc: 0.8928 - val_loss: 1.4791 - val_acc: 0.9056\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 4s 82us/step - loss: 0.3717 - acc: 0.8963 - val_loss: 1.4312 - val_acc: 0.9089\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 4s 83us/step - loss: 0.3597 - acc: 0.8984 - val_loss: 1.4080 - val_acc: 0.9108\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 4s 85us/step - loss: 0.3498 - acc: 0.9007 - val_loss: 1.3941 - val_acc: 0.9119\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 4s 82us/step - loss: 0.3411 - acc: 0.9023 - val_loss: 1.3503 - val_acc: 0.9145\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 4s 82us/step - loss: 0.3336 - acc: 0.9040 - val_loss: 1.3274 - val_acc: 0.9167\n",
            "Test loss: 0.3065038785815239\n",
            "Test accuracy: 0.9153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1AlIsE2bfKO-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN with 2 Hidden layer 128 kernels (with size 3x3 and maxpooling of 2x2 followed by a feed forward layer with 512 units"
      ]
    },
    {
      "metadata": {
        "id": "jcjZf0_RfTdU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def CNN_2hidden(batchsize,lr):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3),\n",
        "                     activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    sgd = optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=False)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batchsize,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCmfEeOcsH9k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Batch Size =1024 Learning rate =0.1"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "7ad56bce-7e74-447a-a9b1-5ae68af0f5ca",
        "id": "xrta6iyUfdqa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "CNN_2hidden(1024,0.1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 559,882\n",
            "Trainable params: 559,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 2.2722 - acc: 0.1949 - val_loss: 9.5519 - val_acc: 0.2806\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 2.1855 - acc: 0.4883 - val_loss: 5.6301 - val_acc: 0.5730\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.9907 - acc: 0.6498 - val_loss: 4.2751 - val_acc: 0.7066\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 1.5258 - acc: 0.7215 - val_loss: 3.3406 - val_acc: 0.7836\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.9532 - acc: 0.7940 - val_loss: 2.4943 - val_acc: 0.8403\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.6524 - acc: 0.8366 - val_loss: 2.1078 - val_acc: 0.8652\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.5216 - acc: 0.8618 - val_loss: 1.8164 - val_acc: 0.8844\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.4537 - acc: 0.8751 - val_loss: 1.6517 - val_acc: 0.8956\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.4090 - acc: 0.8866 - val_loss: 1.5913 - val_acc: 0.8998\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.3804 - acc: 0.8920 - val_loss: 1.4409 - val_acc: 0.9086\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 0.3572 - acc: 0.8983 - val_loss: 1.3726 - val_acc: 0.9131\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.3364 - acc: 0.9037 - val_loss: 1.3194 - val_acc: 0.9165\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.3206 - acc: 0.9074 - val_loss: 1.2755 - val_acc: 0.9197\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.3086 - acc: 0.9113 - val_loss: 1.2207 - val_acc: 0.9227\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 0.2941 - acc: 0.9145 - val_loss: 1.1605 - val_acc: 0.9263\n",
            "Test loss: 0.26811350446343424\n",
            "Test accuracy: 0.9224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WZgfJNzVf9VW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Batch size:1024; lr=0.1; With the addition of one hidden layer the accuracy has increased from 91.5 to 92.2 **\n",
        "\n",
        "one hidden layer :- Trainable params: 2,771,594\n",
        "Two hidden layer:- Trainable params: 559,882 \n",
        "\n",
        "\n",
        "## Batch Size =128; learning rate =0.1"
      ]
    },
    {
      "metadata": {
        "id": "cS1at0FTgjW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "bfb2a623-7308-4ec6-9030-25a67615d46d"
      },
      "cell_type": "code",
      "source": [
        "CNN_2hidden(128,0.1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 559,882\n",
            "Trainable params: 559,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 9s 176us/step - loss: 1.4434 - acc: 0.5968 - val_loss: 2.1088 - val_acc: 0.8670\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 8s 166us/step - loss: 0.3870 - acc: 0.8844 - val_loss: 1.2902 - val_acc: 0.9183\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 8s 162us/step - loss: 0.2800 - acc: 0.9155 - val_loss: 1.1249 - val_acc: 0.9291\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.2225 - acc: 0.9333 - val_loss: 0.9426 - val_acc: 0.9404\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 8s 162us/step - loss: 0.1822 - acc: 0.9450 - val_loss: 0.6944 - val_acc: 0.9557\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.1540 - acc: 0.9541 - val_loss: 0.5621 - val_acc: 0.9644\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 8s 164us/step - loss: 0.1336 - acc: 0.9597 - val_loss: 0.5869 - val_acc: 0.9627\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 0.1174 - acc: 0.9649 - val_loss: 0.4827 - val_acc: 0.9696\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 8s 162us/step - loss: 0.1067 - acc: 0.9676 - val_loss: 0.4608 - val_acc: 0.9709\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.0974 - acc: 0.9710 - val_loss: 0.3957 - val_acc: 0.9751\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 0.0907 - acc: 0.9720 - val_loss: 0.3874 - val_acc: 0.9756\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 9s 170us/step - loss: 0.0844 - acc: 0.9751 - val_loss: 0.3718 - val_acc: 0.9766\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 8s 165us/step - loss: 0.0792 - acc: 0.9757 - val_loss: 0.3773 - val_acc: 0.9763\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.0737 - acc: 0.9778 - val_loss: 0.3526 - val_acc: 0.9779\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.0716 - acc: 0.9777 - val_loss: 0.3094 - val_acc: 0.9805\n",
            "Test loss: 0.07200224391445517\n",
            "Test accuracy: 0.9774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uCQ1Z1ygsdm-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### By Reducing batch size from 1024 to 128 there is frequent update so the accuracy has improved from 92% to 97%\n",
        "\n",
        "## Batch Size =32 and Learning rate =0.1"
      ]
    },
    {
      "metadata": {
        "id": "K-Uzk5SBgPj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "3680e660-a1a7-4254-af15-f2a3eae4377e"
      },
      "cell_type": "code",
      "source": [
        "CNN_2hidden(32,0.1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 559,882\n",
            "Trainable params: 559,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 20s 403us/step - loss: 0.5731 - acc: 0.8333 - val_loss: 0.9107 - val_acc: 0.9426\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 18s 358us/step - loss: 0.1613 - acc: 0.9506 - val_loss: 0.5520 - val_acc: 0.9653\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 17s 349us/step - loss: 0.1081 - acc: 0.9678 - val_loss: 0.5902 - val_acc: 0.9627\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 18s 351us/step - loss: 0.0846 - acc: 0.9737 - val_loss: 0.3268 - val_acc: 0.9792\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.0725 - acc: 0.9783 - val_loss: 0.3381 - val_acc: 0.9787\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 18s 353us/step - loss: 0.0622 - acc: 0.9808 - val_loss: 0.3497 - val_acc: 0.9779\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 17s 348us/step - loss: 0.0554 - acc: 0.9831 - val_loss: 0.3062 - val_acc: 0.9806\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.0500 - acc: 0.9847 - val_loss: 0.2576 - val_acc: 0.9837\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 18s 356us/step - loss: 0.0451 - acc: 0.9862 - val_loss: 0.2602 - val_acc: 0.9835\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 19s 377us/step - loss: 0.0410 - acc: 0.9872 - val_loss: 0.2292 - val_acc: 0.9856\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 0.0385 - acc: 0.9876 - val_loss: 0.2308 - val_acc: 0.9855\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 18s 367us/step - loss: 0.0350 - acc: 0.9892 - val_loss: 0.2132 - val_acc: 0.9866\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 19s 375us/step - loss: 0.0322 - acc: 0.9895 - val_loss: 0.2772 - val_acc: 0.9825\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 18s 363us/step - loss: 0.0308 - acc: 0.9902 - val_loss: 0.2220 - val_acc: 0.9859\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.0283 - acc: 0.9912 - val_loss: 0.1988 - val_acc: 0.9875\n",
            "Test loss: 0.03605588006228209\n",
            "Test accuracy: 0.9894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iNtLtabSs7ay",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### By reducing batch size from 128 to 32 the accuracy has improved significantly to 98.7% from 97%\n",
        "\n",
        "### Training time for 15 iteration also doubled\n",
        "\n",
        "## BatchSize =1 learning rate =0.1 "
      ]
    },
    {
      "metadata": {
        "id": "44GkhlUZizNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1339
        },
        "outputId": "cd09e9d2-ce62-4cf9-dd2a-56a3e7714dbc"
      },
      "cell_type": "code",
      "source": [
        "CNN_2hidden(1,0.1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 559,882\n",
            "Trainable params: 559,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 296s 6ms/step - loss: 0.1299 - acc: 0.9589 - val_loss: 0.4368 - val_acc: 0.9726\n",
            "Epoch 2/15\n",
            "18193/50000 [=========>....................] - ETA: 2:58 - loss: 0.0462 - acc: 0.9857"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-997d9a2c3e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCNN_2hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-21e9eebbe2a9>\u001b[0m in \u001b[0;36mCNN_2hidden\u001b[0;34m(batchsize, lr)\u001b[0m\n\u001b[1;32m     25\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_ZdMzzVUtW4Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**With Batchsize of 1 Training compute is heavy so interupted in single iteration.**\n",
        "\n",
        "**Here update is after each sample so for the single iteration accuracy achieved is 97%.**\n",
        "\n",
        "**Its Computation need makes it inefficient in terms of time complexity **\n",
        "\n",
        "### Batch size of 32 would be appropriate for MNIST dataset interms of accuracy(98.9%) as well as training time "
      ]
    },
    {
      "metadata": {
        "id": "olOfh0N7ucPQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lets investigate Learning rate\n",
        "\n",
        "## Learning rate =0.05  Batch size =32 \n",
        "\n",
        "### Learning rate is halved"
      ]
    },
    {
      "metadata": {
        "id": "kKud-OGDkeLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "a12e0cb4-64a9-405d-fb34-b00d6127c428"
      },
      "cell_type": "code",
      "source": [
        "CNN_2hidden(32,0.05)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 559,882\n",
            "Trainable params: 559,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 17s 331us/step - loss: 0.5872 - acc: 0.8331 - val_loss: 0.8186 - val_acc: 0.9485\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 16s 325us/step - loss: 0.1655 - acc: 0.9499 - val_loss: 0.4907 - val_acc: 0.9691\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 0.1096 - acc: 0.9664 - val_loss: 0.5178 - val_acc: 0.9678\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 16s 320us/step - loss: 0.0857 - acc: 0.9735 - val_loss: 0.3654 - val_acc: 0.9771\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 16s 320us/step - loss: 0.0716 - acc: 0.9784 - val_loss: 0.4163 - val_acc: 0.9740\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 16s 321us/step - loss: 0.0625 - acc: 0.9809 - val_loss: 0.3085 - val_acc: 0.9805\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 0.0553 - acc: 0.9825 - val_loss: 0.3175 - val_acc: 0.9799\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 16s 325us/step - loss: 0.0493 - acc: 0.9852 - val_loss: 0.2732 - val_acc: 0.9827\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 16s 323us/step - loss: 0.0449 - acc: 0.9863 - val_loss: 0.2685 - val_acc: 0.9828\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 16s 324us/step - loss: 0.0409 - acc: 0.9876 - val_loss: 0.2385 - val_acc: 0.9848\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 16s 320us/step - loss: 0.0380 - acc: 0.9881 - val_loss: 0.2663 - val_acc: 0.9834\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 16s 322us/step - loss: 0.0352 - acc: 0.9890 - val_loss: 0.2442 - val_acc: 0.9846\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 16s 321us/step - loss: 0.0320 - acc: 0.9900 - val_loss: 0.3152 - val_acc: 0.9804\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 16s 324us/step - loss: 0.0303 - acc: 0.9905 - val_loss: 0.2551 - val_acc: 0.9839\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 16s 327us/step - loss: 0.0283 - acc: 0.9915 - val_loss: 0.2244 - val_acc: 0.9859\n",
            "Test loss: 0.03533322144212434\n",
            "Test accuracy: 0.9883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r_4_kdG2vYoR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### With learning rate of 0.05 accuracy achieved is almost the same as 0.1 learning rate"
      ]
    },
    {
      "metadata": {
        "id": "SIpXFSaJvE_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Learning rate =0.01  Batch size =32 "
      ]
    },
    {
      "metadata": {
        "id": "ci7GG2vOlkkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "83b3c552-1a9a-47be-8bc9-08df046dbe62"
      },
      "cell_type": "code",
      "source": [
        "CNN_2hidden(32,0.01)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 559,882\n",
            "Trainable params: 559,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 18s 350us/step - loss: 0.5703 - acc: 0.8425 - val_loss: 0.7521 - val_acc: 0.9525\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.1560 - acc: 0.9532 - val_loss: 0.5328 - val_acc: 0.9661\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 17s 343us/step - loss: 0.1056 - acc: 0.9678 - val_loss: 0.4716 - val_acc: 0.9701\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 17s 340us/step - loss: 0.0843 - acc: 0.9739 - val_loss: 0.3743 - val_acc: 0.9764\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 18s 368us/step - loss: 0.0709 - acc: 0.9783 - val_loss: 0.3264 - val_acc: 0.9795\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 26s 512us/step - loss: 0.0615 - acc: 0.9817 - val_loss: 0.2919 - val_acc: 0.9816\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 34s 674us/step - loss: 0.0547 - acc: 0.9833 - val_loss: 0.2940 - val_acc: 0.9814\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 33s 669us/step - loss: 0.0493 - acc: 0.9847 - val_loss: 0.2755 - val_acc: 0.9826\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.0444 - acc: 0.9864 - val_loss: 0.2906 - val_acc: 0.9817\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 18s 362us/step - loss: 0.0408 - acc: 0.9877 - val_loss: 0.2272 - val_acc: 0.9855\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 0.0381 - acc: 0.9879 - val_loss: 0.2353 - val_acc: 0.9854\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 0.0351 - acc: 0.9890 - val_loss: 0.2464 - val_acc: 0.9847\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 16s 328us/step - loss: 0.0319 - acc: 0.9900 - val_loss: 0.2493 - val_acc: 0.9844\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 19s 376us/step - loss: 0.0297 - acc: 0.9907 - val_loss: 0.2431 - val_acc: 0.9847\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 20s 398us/step - loss: 0.0278 - acc: 0.9915 - val_loss: 0.2786 - val_acc: 0.9825\n",
            "Test loss: 0.04565000851629302\n",
            "Test accuracy: 0.9843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "np1DOzBKwJSa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### By reducing learning rate to 0.01 update will be slower than 0.1 so the accuracy achieved is 98.4 which 0.5% less\n",
        "\n",
        "## Learning rate =0.01  Batch size =32 "
      ]
    },
    {
      "metadata": {
        "id": "egBXaf60pAY0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "cdfc5e8f-6fe2-452f-ee02-66578289f790"
      },
      "cell_type": "code",
      "source": [
        "CNN_2hidden(32,0.001)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 559,882\n",
            "Trainable params: 559,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 20s 396us/step - loss: 0.5898 - acc: 0.8347 - val_loss: 0.9027 - val_acc: 0.9429\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 0.1503 - acc: 0.9537 - val_loss: 0.4378 - val_acc: 0.9721\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 19s 385us/step - loss: 0.1029 - acc: 0.9677 - val_loss: 0.4352 - val_acc: 0.9726\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 0.0810 - acc: 0.9754 - val_loss: 0.3992 - val_acc: 0.9748\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 19s 372us/step - loss: 0.0684 - acc: 0.9795 - val_loss: 0.3318 - val_acc: 0.9791\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 18s 368us/step - loss: 0.0597 - acc: 0.9811 - val_loss: 0.2788 - val_acc: 0.9824\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 18s 370us/step - loss: 0.0529 - acc: 0.9839 - val_loss: 0.2910 - val_acc: 0.9816\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 19s 372us/step - loss: 0.0475 - acc: 0.9854 - val_loss: 0.2623 - val_acc: 0.9834\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 18s 366us/step - loss: 0.0434 - acc: 0.9868 - val_loss: 0.2740 - val_acc: 0.9829\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 18s 362us/step - loss: 0.0390 - acc: 0.9881 - val_loss: 0.2462 - val_acc: 0.9847\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 18s 359us/step - loss: 0.0367 - acc: 0.9890 - val_loss: 0.2114 - val_acc: 0.9865\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 18s 360us/step - loss: 0.0331 - acc: 0.9894 - val_loss: 0.2388 - val_acc: 0.9850\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 18s 360us/step - loss: 0.0316 - acc: 0.9903 - val_loss: 0.2281 - val_acc: 0.9856\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 18s 359us/step - loss: 0.0289 - acc: 0.9912 - val_loss: 0.2203 - val_acc: 0.9858\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 18s 362us/step - loss: 0.0268 - acc: 0.9917 - val_loss: 0.2683 - val_acc: 0.9831\n",
            "Test loss: 0.04502233474935056\n",
            "Test accuracy: 0.9854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RVk0JYv1wv2n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### By reducing learning rate to 0.001 update will be slower than 0.1 so the accuracy achieved is 98.4 which 0.5% less\n",
        "\n",
        "#### Accuracy achieved is almost similar to the 0.01 learning rate\n",
        "\n",
        "\n",
        "## CNN 2 hidden layer networks performs better than 1 hidden layer network; Deep networks provides extra dimensional freedom for classification\n",
        "\n",
        "## For the CNN 2 hidden layer architecture; Batch size =32 and Learning rate =0.1 The accuracy achieved is the highest validation accuracy : 98.75%; Training Accuracy : 99.12;Test Accuracy :98.9%"
      ]
    }
  ]
}