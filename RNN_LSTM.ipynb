{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lutm6KrMCPT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout,BatchNormalization\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU \n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras import initializers\n",
        "import keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABkAfKg_sKv1",
        "colab_type": "text"
      },
      "source": [
        "## Getting Mnist data and reshaping for RNN & LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVPTaT3QHR1x",
        "colab_type": "code",
        "outputId": "a8082f90-b6fc-4221-d99b-109ab6721d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 15\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x, y), (x_test, y_test) = mnist.load_data()\n",
        "x = x.reshape(-1,28,28)\n",
        "x_test = x_test.reshape(-1,28,28)\n",
        "#print(x1_train.shape,x1_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "x = x.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x[0:50000]\n",
        "x_val = x[50000::]\n",
        "\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x.shape)\n",
        "print(x_train.shape, 'train samples')\n",
        "print(x_val.shape, 'validation samples')\n",
        "print(x_test.shape, 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y = keras.utils.to_categorical(y, num_classes)\n",
        "y_train = y[0:50000]\n",
        "y_val=y[50000::]\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(50000, 28, 28) train samples\n",
            "(10000, 28, 28) validation samples\n",
            "(10000, 28, 28) test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y840p-MBeHpi",
        "colab_type": "text"
      },
      "source": [
        "## RNN without batch normalization and dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi7YH5DqMQ4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def RNN(batchsize,lr):\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(units=512, activation='relu', input_shape=(28,28)))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    sgd = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=False)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batchsize,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        validation_data=(x_val, y_val))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('test loss:', score[0])\n",
        "    print('test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "komDxJxWKlPH",
        "colab_type": "text"
      },
      "source": [
        "## Learning rate =0.01 and Batchsize =128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLhuyBbQO7RN",
        "colab_type": "code",
        "outputId": "4904ca11-f3da-46be-cbfa-5ac802c6f8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "RNN(batchsize=128,lr=0.01)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 512)               276992    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 282,122\n",
            "Trainable params: 282,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 1.4852 - acc: 0.4953 - val_loss: 5.1837 - val_acc: 0.6742\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.4007 - acc: 0.8756 - val_loss: 1.2570 - val_acc: 0.9208\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 8s 157us/step - loss: 0.2225 - acc: 0.9321 - val_loss: 0.8666 - val_acc: 0.9451\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 0.1639 - acc: 0.9495 - val_loss: 0.8637 - val_acc: 0.9452\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.1313 - acc: 0.9594 - val_loss: 0.6625 - val_acc: 0.9584\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.1121 - acc: 0.9652 - val_loss: 0.5791 - val_acc: 0.9632\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 7s 137us/step - loss: 0.0977 - acc: 0.9710 - val_loss: 0.4699 - val_acc: 0.9701\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.0868 - acc: 0.9725 - val_loss: 0.5366 - val_acc: 0.9660\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 8s 154us/step - loss: 0.0780 - acc: 0.9759 - val_loss: 0.4931 - val_acc: 0.9689\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 7s 143us/step - loss: 0.0705 - acc: 0.9789 - val_loss: 0.3832 - val_acc: 0.9759\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 7s 148us/step - loss: 0.0635 - acc: 0.9801 - val_loss: 0.4082 - val_acc: 0.9742\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.0589 - acc: 0.9812 - val_loss: 0.7953 - val_acc: 0.9492\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 0.0554 - acc: 0.9825 - val_loss: 0.3960 - val_acc: 0.9749\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 8s 161us/step - loss: 0.0498 - acc: 0.9846 - val_loss: 0.4059 - val_acc: 0.9743\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.0453 - acc: 0.9859 - val_loss: 0.3555 - val_acc: 0.9775\n",
            "test loss: 0.06476740560053149\n",
            "test accuracy: 0.9791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PYBKFB8spgm",
        "colab_type": "text"
      },
      "source": [
        "### Training Accuracy achieved : 98.6% \n",
        "### Testing acuracy achieved : 97.9%\n",
        "### we will try batch normalization for the convergence speed and dropout to improve accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu4CD0SbhcLM",
        "colab_type": "text"
      },
      "source": [
        "## RNN with batchnormalisation and dropout layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtDOEPX8haFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def RNN(batchsize,lr):\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(units=512, activation='relu', input_shape=(28,28)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    sgd = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=False)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batchsize,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        validation_data=(x_val, y_val))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('test loss:', score[0])\n",
        "    print('test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zzjh_i2hnuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "667eb460-2e19-4a41-e81f-0222a15c2e52"
      },
      "source": [
        "RNN(batchsize=128,lr=0.01)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_2 (SimpleRNN)     (None, 512)               276992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 284,170\n",
            "Trainable params: 283,146\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 8s 152us/step - loss: 0.6544 - acc: 0.7801 - val_loss: 4.2784 - val_acc: 0.7312\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 0.2088 - acc: 0.9349 - val_loss: 3.1052 - val_acc: 0.8040\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 0.1347 - acc: 0.9586 - val_loss: 3.4989 - val_acc: 0.7785\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 8s 154us/step - loss: 0.1036 - acc: 0.9683 - val_loss: 2.5659 - val_acc: 0.8375\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 8s 159us/step - loss: 0.0845 - acc: 0.9747 - val_loss: 1.9808 - val_acc: 0.8742\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 0.0743 - acc: 0.9773 - val_loss: 3.4176 - val_acc: 0.7852\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 7s 144us/step - loss: 0.0634 - acc: 0.9805 - val_loss: 2.2486 - val_acc: 0.8577\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.0580 - acc: 0.9817 - val_loss: 1.9554 - val_acc: 0.8772\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 0.0500 - acc: 0.9845 - val_loss: 1.6533 - val_acc: 0.8950\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 0.0445 - acc: 0.9862 - val_loss: 2.5367 - val_acc: 0.8402\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.0396 - acc: 0.9877 - val_loss: 2.2814 - val_acc: 0.8569\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.0373 - acc: 0.9883 - val_loss: 2.3988 - val_acc: 0.8485\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 0.0348 - acc: 0.9891 - val_loss: 2.5753 - val_acc: 0.8366\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 0.0304 - acc: 0.9910 - val_loss: 2.7077 - val_acc: 0.8296\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 8s 159us/step - loss: 0.0281 - acc: 0.9911 - val_loss: 2.0726 - val_acc: 0.8703\n",
            "test loss: 0.06795864828417543\n",
            "test accuracy: 0.9806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcRmcRg3tO5m",
        "colab_type": "text"
      },
      "source": [
        "### with batch normalization the convergence is fast we achieved previous training accuracy 98% in 8 iteration itself\n",
        "\n",
        "### With dropout based regularization can be used at the times of overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw6Houkbsnvw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxSbZ6yOho-j",
        "colab_type": "text"
      },
      "source": [
        "### Learning rate =0.1 Batchsize = 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSacuaPChyQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "3e5850c8-ac79-4d7d-c2f6-5d657d688bc4"
      },
      "source": [
        "RNN(batchsize=128,lr=0.1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_3 (SimpleRNN)     (None, 512)               276992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 284,170\n",
            "Trainable params: 283,146\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.6634 - acc: 0.7792 - val_loss: 4.1811 - val_acc: 0.7376\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 8s 153us/step - loss: 0.2098 - acc: 0.9348 - val_loss: 2.3595 - val_acc: 0.8505\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 8s 164us/step - loss: 0.1358 - acc: 0.9579 - val_loss: 1.8337 - val_acc: 0.8832\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 8s 160us/step - loss: 0.1078 - acc: 0.9667 - val_loss: 2.4515 - val_acc: 0.8457\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 8s 153us/step - loss: 0.0866 - acc: 0.9742 - val_loss: 1.9743 - val_acc: 0.8744\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 8s 154us/step - loss: 0.0754 - acc: 0.9766 - val_loss: 2.1488 - val_acc: 0.8641\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 8s 156us/step - loss: 0.0655 - acc: 0.9795 - val_loss: 2.6093 - val_acc: 0.8347\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 8s 154us/step - loss: 0.0565 - acc: 0.9824 - val_loss: 2.8984 - val_acc: 0.8175\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 8s 153us/step - loss: 0.0523 - acc: 0.9838 - val_loss: 2.0031 - val_acc: 0.8739\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 8s 151us/step - loss: 0.0452 - acc: 0.9859 - val_loss: 2.6322 - val_acc: 0.8331\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.0423 - acc: 0.9865 - val_loss: 2.4640 - val_acc: 0.8436\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 0.0366 - acc: 0.9889 - val_loss: 1.5117 - val_acc: 0.9040\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 0.0350 - acc: 0.9896 - val_loss: 1.6217 - val_acc: 0.8968\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 8s 155us/step - loss: 0.0305 - acc: 0.9903 - val_loss: 1.3318 - val_acc: 0.9155\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 8s 153us/step - loss: 0.0278 - acc: 0.9917 - val_loss: 1.6610 - val_acc: 0.8946\n",
            "test loss: 0.06093739502064418\n",
            "test accuracy: 0.9821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x42_RqYAupwz",
        "colab_type": "text"
      },
      "source": [
        "### Changing learning rate to 0.1 provides fast gradient update\n",
        "### Training accuracy : 99.17%\n",
        "### Testing accuracy : 98.21%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi73ca4zpgXK",
        "colab_type": "text"
      },
      "source": [
        "## Learning rate =0.1 Batchsize=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QraXvoopvKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "b6e1e2f4-e815-4eca-b486-57f474b4de86"
      },
      "source": [
        "RNN(batchsize=1,lr=0.1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_4 (SimpleRNN)     (None, 512)               276992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 284,170\n",
            "Trainable params: 283,146\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "37018/50000 [=====================>........] - ETA: 3:27 - loss: 2.3079 - acc: 0.1042"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-b6c48be4b034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-5f5062dc9533>\u001b[0m in \u001b[0;36mRNN\u001b[0;34m(batchsize, lr)\u001b[0m\n\u001b[1;32m     17\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                        validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     20\u001b[0m    \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgBiZD0ovFU8",
        "colab_type": "text"
      },
      "source": [
        "### With batch size of 1 the convergence will be very slow\n",
        "### Batch size of 1 is taking more time so due to compute restriction we stopped the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyOqM6JFMuQF",
        "colab_type": "text"
      },
      "source": [
        "## LSTM with one layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zndlbVLoPLo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTMnet(batchsize,lr):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(28,28), activation='relu', return_sequences=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    sgd = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=False)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batchsize,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        validation_data=(x_val, y_val))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('test loss:', score[0])\n",
        "    print('test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUdl4epiPbB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "6d5a2cc8-f8d0-4f70-90e3-573b84abf878"
      },
      "source": [
        "LSTMnet(batchsize=128,lr=0.01)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_17 (LSTM)               (None, 128)               80384     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 82,186\n",
            "Trainable params: 81,930\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 24s 487us/step - loss: 1.4689 - acc: 0.5123 - val_loss: 13.7692 - val_acc: 0.1455\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 20s 396us/step - loss: 0.7769 - acc: 0.7476 - val_loss: 13.4833 - val_acc: 0.1634\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 20s 396us/step - loss: 0.4899 - acc: 0.8465 - val_loss: 13.6085 - val_acc: 0.1557\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.3432 - acc: 0.8939 - val_loss: 13.7717 - val_acc: 0.1455\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 0.2563 - acc: 0.9206 - val_loss: 13.9306 - val_acc: 0.1356\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 21s 413us/step - loss: 0.2048 - acc: 0.9379 - val_loss: 13.9836 - val_acc: 0.1324\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 20s 396us/step - loss: 0.1748 - acc: 0.9468 - val_loss: 14.0126 - val_acc: 0.1305\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.1557 - acc: 0.9530 - val_loss: 14.0494 - val_acc: 0.1281\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 20s 396us/step - loss: 0.1417 - acc: 0.9573 - val_loss: 14.1575 - val_acc: 0.1216\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 0.1312 - acc: 0.9596 - val_loss: 14.2231 - val_acc: 0.1174\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 0.1202 - acc: 0.9636 - val_loss: 14.1549 - val_acc: 0.1216\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 0.1121 - acc: 0.9651 - val_loss: 13.9499 - val_acc: 0.1344\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 0.1062 - acc: 0.9677 - val_loss: 13.9784 - val_acc: 0.1326\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 0.0998 - acc: 0.9696 - val_loss: 14.0899 - val_acc: 0.1257\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.0948 - acc: 0.9704 - val_loss: 14.0347 - val_acc: 0.1292\n",
            "test loss: 0.1474612377241254\n",
            "test accuracy: 0.9531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzq0GtUJyIpi",
        "colab_type": "text"
      },
      "source": [
        "### Training accuracy achieved : 97%\n",
        "### Testing accuracy achieved: 95.3%\n",
        "\n",
        "### Lets improve accuracy using two more hidden layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kJ92961PsGq",
        "colab_type": "text"
      },
      "source": [
        "## LSTM with two layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52h6wRQ8K3Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTMnet(batchsize,lr):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(28,28), activation='relu', return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(LSTM(128, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    sgd = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=False)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batchsize,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        validation_data=(x_val, y_val))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('test loss:', score[0])\n",
        "    print('test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5KEdlUoLdRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "795003be-f5da-4ecb-f0e4-1c3c18a28340"
      },
      "source": [
        "LSTMnet(batchsize=128,lr=0.01)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_12 (LSTM)               (None, 28, 128)           80384     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 28, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 230,282\n",
            "Trainable params: 230,026\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 42s 837us/step - loss: 1.8665 - acc: 0.3269 - val_loss: 13.4159 - val_acc: 0.1660\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 38s 766us/step - loss: 1.1730 - acc: 0.5945 - val_loss: 13.0398 - val_acc: 0.1898\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 39s 774us/step - loss: 0.6831 - acc: 0.7749 - val_loss: 13.2727 - val_acc: 0.1752\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 38s 756us/step - loss: 0.4671 - acc: 0.8550 - val_loss: 13.4230 - val_acc: 0.1663\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 38s 768us/step - loss: 0.3659 - acc: 0.8912 - val_loss: 13.2208 - val_acc: 0.1784\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 37s 750us/step - loss: 0.2986 - acc: 0.9139 - val_loss: 13.4274 - val_acc: 0.1660\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 39s 772us/step - loss: 0.2533 - acc: 0.9291 - val_loss: 13.4282 - val_acc: 0.1658\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 38s 764us/step - loss: 0.2274 - acc: 0.9367 - val_loss: 13.3752 - val_acc: 0.1696\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 39s 771us/step - loss: 0.1979 - acc: 0.9450 - val_loss: 13.5681 - val_acc: 0.1577\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 37s 749us/step - loss: 0.1826 - acc: 0.9500 - val_loss: 13.4345 - val_acc: 0.1659\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 40s 794us/step - loss: 0.1611 - acc: 0.9557 - val_loss: 13.5447 - val_acc: 0.1592\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 37s 748us/step - loss: 0.1485 - acc: 0.9585 - val_loss: 13.4817 - val_acc: 0.1630\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 39s 771us/step - loss: 0.1373 - acc: 0.9621 - val_loss: 13.6255 - val_acc: 0.1544\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 37s 750us/step - loss: 0.1266 - acc: 0.9652 - val_loss: 13.5292 - val_acc: 0.1601\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 38s 770us/step - loss: 0.1209 - acc: 0.9678 - val_loss: 13.6910 - val_acc: 0.1501\n",
            "test loss: 0.08055952830772439\n",
            "test accuracy: 0.9758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmoEulDhwd0O",
        "colab_type": "text"
      },
      "source": [
        "### With addition of two hidden layer the accuract has improved by 2%\n",
        "### Test accuracy : 97.5%\n",
        "### Train accuracy : 96.7%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXutBKXJw8Cv",
        "colab_type": "text"
      },
      "source": [
        "##  Learning rate =0.1 and Batchsize =128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCSFGpsZRtfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "f0a6532b-1ba7-49fb-9a28-5d6285fab225"
      },
      "source": [
        "LSTMnet(batchsize=128,lr=0.1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_14 (LSTM)               (None, 28, 128)           80384     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 28, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 28, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 230,282\n",
            "Trainable params: 230,026\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 42s 840us/step - loss: 1.9220 - acc: 0.3057 - val_loss: 13.8209 - val_acc: 0.1415\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 39s 776us/step - loss: 1.2248 - acc: 0.5769 - val_loss: 13.2080 - val_acc: 0.1801\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 39s 781us/step - loss: 0.7113 - acc: 0.7648 - val_loss: 13.8498 - val_acc: 0.1406\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 39s 775us/step - loss: 0.4759 - acc: 0.8508 - val_loss: 13.9379 - val_acc: 0.1351\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 38s 754us/step - loss: 0.3533 - acc: 0.8950 - val_loss: 13.9041 - val_acc: 0.1369\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 39s 774us/step - loss: 0.2827 - acc: 0.9181 - val_loss: 13.9304 - val_acc: 0.1355\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 38s 752us/step - loss: 0.2375 - acc: 0.9330 - val_loss: 13.5364 - val_acc: 0.1598\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 39s 785us/step - loss: 0.2105 - acc: 0.9414 - val_loss: 13.6408 - val_acc: 0.1533\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 38s 750us/step - loss: 0.1887 - acc: 0.9471 - val_loss: 13.4368 - val_acc: 0.1657\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 39s 773us/step - loss: 0.1691 - acc: 0.9538 - val_loss: 13.2354 - val_acc: 0.1776\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 38s 770us/step - loss: 0.1561 - acc: 0.9570 - val_loss: 13.3279 - val_acc: 0.1725\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 39s 779us/step - loss: 0.1453 - acc: 0.9599 - val_loss: 13.6037 - val_acc: 0.1554\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 37s 749us/step - loss: 0.1316 - acc: 0.9647 - val_loss: 13.4148 - val_acc: 0.1671\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 39s 771us/step - loss: 0.1229 - acc: 0.9659 - val_loss: 13.4044 - val_acc: 0.1674\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 38s 750us/step - loss: 0.1189 - acc: 0.9676 - val_loss: 13.4604 - val_acc: 0.1638\n",
            "test loss: 0.103494365889334\n",
            "test accuracy: 0.9776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdBtzUQfxLeR",
        "colab_type": "text"
      },
      "source": [
        "### With learning rate of 0.1 the gradient update is faster and testing accuracy improved by 0.5%\n",
        "### Testing accuracy 97.7%\n",
        "### Traing accuracy 96.7#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in9Q498Tx8od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "97fbf343-93d5-42f7-bb30-c6372882e970"
      },
      "source": [
        "LSTMnet(batchsize=1,lr=0.1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_19 (LSTM)               (None, 128)               80384     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 82,186\n",
            "Trainable params: 81,930\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "24971/50000 [=============>................] - ETA: 19:13 - loss: 2.3078 - acc: 0.1026"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-43720bc05868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLSTMnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-a93c6eeb6b9f>\u001b[0m in \u001b[0;36mLSTMnet\u001b[0;34m(batchsize, lr)\u001b[0m\n\u001b[1;32m     17\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                         validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg7yEZcwzGxi",
        "colab_type": "text"
      },
      "source": [
        "### With batch size of 1 the convergence will be very slow\n",
        "### Batch size of 1 is taking more time so due to compute restriction we stopped the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVUJenPUw6kX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}